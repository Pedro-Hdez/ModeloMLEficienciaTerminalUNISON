{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5222f547-29bd-42b8-b9fc-e351edad680a",
   "metadata": {},
   "source": [
    "# Descarga de los datos\n",
    "\n",
    "En esta libreta se exponen los pasos a seguir para descargar los datos desde el repositorio original."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944ce3e7-919a-4285-97bd-21af61bea59a",
   "metadata": {},
   "source": [
    "Primero se obtienen las credenciales del repositorio de datos y las direcciones de los archivos a descargar. Por razones de seguridad, tanto las credenciales como las URLs de los archivos permanecerán ocultas.\n",
    "\n",
    "Después, todos los archivos se descargan, se les corrige su schema y finalmente se almacenan en una carpeta local como archivos .pkl con el objetivo de no repetir el proceso de descarga más de una vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ad48577-ba21-42cb-9937-7c19ee79ee85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Credenciales\n",
    "creds = json.load(open('../secrets/credentials.json'))\n",
    "USER = creds['username']\n",
    "PASSWORD = creds['password']\n",
    "\n",
    "# Archivos a descargar\n",
    "files = json.load(open('../secrets/files.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ab151b-165a-4b7c-987f-806bb84b4ffc",
   "metadata": {},
   "source": [
    "## 1.1 Datos del Proceso de Admisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9a717a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencias\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "from modules.loadAndClean import downloadAndCorrectSchema\n",
    "\n",
    "# Path de los schemas\n",
    "schemas_path = '../schemas'\n",
    "\n",
    "# Límites de renglones y columnas a mostrar al imprimir DFs\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e2ec24b-6285-4b5f-b318-088f5d696cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Periodo 2012-2018 ----------\n",
    "# Admitidos\n",
    "dfA_2012_2018 = downloadAndCorrectSchema(\n",
    "    files['procesoAdmision']['admitidos_2012-2018'],\n",
    "    USER,\n",
    "    PASSWORD,\n",
    "    'Descargando el archivo de admitidos 2012-2018...',\n",
    "    f'{schemas_path}/procesoAdmision/corregido/admitidos_2012-2018.xlsx'\n",
    ")\n",
    "# Solicitudes Admisión\n",
    "dfS_2012_2018 = downloadAndCorrectSchema(\n",
    "    files['procesoAdmision']['solicitudesAdmision_2012-2018'],\n",
    "    USER,\n",
    "    PASSWORD,\n",
    "    'Descargando el archivo de solicitudes de admisión 2012-2018...',\n",
    "    f'{schemas_path}/procesoAdmision/corregido/solicitudesAdmision_2012-2018.xlsx'\n",
    ")\n",
    "\n",
    "# ---------- Periodo 2019 ----------\n",
    "# Admitidos\n",
    "dfA_2019 = downloadAndCorrectSchema(\n",
    "    files['procesoAdmision']['admitidos_2019'],\n",
    "    USER,\n",
    "    PASSWORD,\n",
    "    'Descargando el archivo de admitidos 2019...',\n",
    "    f'{schemas_path}/procesoAdmision/corregido/admitidos_2019.xlsx'\n",
    ")\n",
    "# Solicitudes Admisión\n",
    "dfS_2019 = downloadAndCorrectSchema(\n",
    "    files['procesoAdmision']['solicitudesAdmision_2019'],\n",
    "    USER,\n",
    "    PASSWORD,\n",
    "    'Descargando el archivo de solicitudes de admisión 2019...',\n",
    "    f'{schemas_path}/procesoAdmision/corregido/solicitudesAdmision_2019.xlsx'\n",
    ")\n",
    "\n",
    "# ---------- Periodo 2020 ----------\n",
    "# Admitidos\n",
    "dfA_2020 = downloadAndCorrectSchema(\n",
    "    files['procesoAdmision']['admitidos_2020'],\n",
    "    USER,\n",
    "    PASSWORD,\n",
    "    'Descargando el archivo de admitidos 2020...',\n",
    "    f'{schemas_path}/procesoAdmision/corregido/admitidos_2020.xlsx'\n",
    ")\n",
    "# Solicitudes Admisión\n",
    "dfS_2020 = downloadAndCorrectSchema(\n",
    "    files['procesoAdmision']['solicitudesAdmision_2020'],\n",
    "    USER,\n",
    "    PASSWORD,\n",
    "    'Descargando el archivo de solicitudes de admisión 2020...',\n",
    "    f'{schemas_path}/procesoAdmision/corregido/solicitudesAdmision_2020.xlsx'\n",
    ")\n",
    "\n",
    "# ---------- Periodo 2021 ----------\n",
    "# Admitidos\n",
    "dfA_2021 = downloadAndCorrectSchema(\n",
    "    files['procesoAdmision']['admitidos_2021'],\n",
    "    USER,\n",
    "    PASSWORD,\n",
    "    'Descargando el archivo de admitidos 2021...',\n",
    "    f'{schemas_path}/procesoAdmision/corregido/admitidos_2021.xlsx'\n",
    ")\n",
    "# Solicitudes Admisión\n",
    "dfS_2021 = downloadAndCorrectSchema(\n",
    "    files['procesoAdmision']['solicitudesAdmision_2021'],\n",
    "    USER,\n",
    "    PASSWORD,\n",
    "    'Descargando el archivo de solicitudes de admisión 2021...',\n",
    "    f'{schemas_path}/procesoAdmision/corregido/solicitudesAdmision_2021.xlsx'\n",
    ")\n",
    "\n",
    "# ---------- Periodo 2022 ----------\n",
    "# Admitidos\n",
    "dfA_2022 = downloadAndCorrectSchema(\n",
    "    files['procesoAdmision']['admitidos_2022'],\n",
    "    USER,\n",
    "    PASSWORD,\n",
    "    'Descargando el archivo de admitidos 2022...',\n",
    "    f'{schemas_path}/procesoAdmision/corregido/admitidos_2022.xlsx'\n",
    ")\n",
    "\n",
    "# Se almacenan los dataframes en una carpeta local\n",
    "dfA_2012_2018.to_pickle('../dfsWithCorrectedSchema/procesoAdmision/dfA_2012_2018.pkl')\n",
    "dfA_2019.to_pickle('../dfsWithCorrectedSchema/procesoAdmision/dfA_2019.pkl')\n",
    "dfA_2020.to_pickle('../dfsWithCorrectedSchema/procesoAdmision/dfA_2020.pkl')\n",
    "dfA_2021.to_pickle('../dfsWithCorrectedSchema/procesoAdmision/dfA_2021.pkl')\n",
    "dfA_2022.to_pickle('../dfsWithCorrectedSchema/procesoAdmision/dfA_2022.pkl')\n",
    "\n",
    "dfS_2012_2018.to_pickle('../dfsWithCorrectedSchema/dfS_2012_2018.pkl')\n",
    "dfS_2019.to_pickle('../dfsWithCorrectedSchema/procesoAdmision/dfS_2019.pkl')\n",
    "dfS_2020.to_pickle('../dfsWithCorrectedSchema/procesoAdmision/dfS_2020.pkl')\n",
    "dfS_2021.to_pickle('../dfsWithCorrectedSchema/procesoAdmision/dfS_2021.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c97214",
   "metadata": {},
   "source": [
    "## 1.2. Datos del perfil de ingreso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8de726aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando los datos del proceso de admisión 2017... OK\n"
     ]
    }
   ],
   "source": [
    "anios = ['2014', '2015', '2016', '2017']\n",
    "folderDfsCorrectedSchema = '../dfsWithCorrectedSchema/perfilIngreso/'\n",
    "if not os.path.exists(folderDfsCorrectedSchema):\n",
    "    os.makedirs(folderDfsCorrectedSchema)\n",
    "\n",
    "for a in anios:\n",
    "    # Se descarga el archivo y se corrige su schema on-the-fly\n",
    "    df = downloadAndCorrectSchema(\n",
    "        files['perfilIngreso'][a],\n",
    "        USER,\n",
    "        PASSWORD,\n",
    "        f'Descargando los datos del proceso de admisión {a}...',\n",
    "        f'{schemas_path}/perfilIngreso/corregido/{a}.xlsx'\n",
    "    )\n",
    "\n",
    "    # Se almacenan el dataframe en una carpeta local\n",
    "    df.to_pickle(f'../dfsWithCorrectedSchema/perfilIngreso/{a}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f33f62",
   "metadata": {},
   "source": [
    "## 1.3. Datos de los reportes históricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80083dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando los datos del reporte histórico 2141... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\pedro\\Documents\\mcd\\proyecto_terminal\\seminario4\\repo\\notebooks\\..\\modules\\loadAndClean.py:36: DtypeWarning: Columns (21,27,29,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(fh, encoding='latin-1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "Descargando los datos del reporte histórico 2142... OK\n",
      "Descargando los datos del reporte histórico 2151... OK\n",
      "Descargando los datos del reporte histórico 2152... OK\n",
      "Descargando los datos del reporte histórico 2161... OK\n",
      "Descargando los datos del reporte histórico 2162... OK\n",
      "Descargando los datos del reporte histórico 2171... OK\n",
      "Descargando los datos del reporte histórico 2172... OK\n",
      "Descargando los datos del reporte histórico 2181... OK\n",
      "Descargando los datos del reporte histórico 2182... OK\n",
      "Descargando los datos del reporte histórico 2191... OK\n",
      "Descargando los datos del reporte histórico 2192... OK\n",
      "Descargando los datos del reporte histórico 2201... OK\n",
      "Descargando los datos del reporte histórico 2202... OK\n",
      "Descargando los datos del reporte histórico 2211... OK\n",
      "Descargando los datos del reporte histórico 2212... OK\n",
      "Descargando los datos del reporte histórico 2221... OK\n",
      "Descargando los datos del reporte histórico 2222... OK\n"
     ]
    }
   ],
   "source": [
    "anios = ['2141', '2142', '2151', '2152', '2161', '2162', '2171', '2172', '2181', '2182','2191','2192','2201','2202','2211', '2212','2221','2222']\n",
    "folderDfsCorrectedSchema = '../dfsWithCorrectedSchema/reportesHistoricos/'\n",
    "if not os.path.exists(folderDfsCorrectedSchema):\n",
    "    os.makedirs(folderDfsCorrectedSchema)\n",
    "\n",
    "for a in anios:\n",
    "    # Se descarga el archivo y se corrige su schema on-the-fly\n",
    "    df = downloadAndCorrectSchema(\n",
    "        files['reportesHistoricos'][a],\n",
    "        USER,\n",
    "        PASSWORD,\n",
    "        f'Descargando los datos del reporte histórico {a}...',\n",
    "        f'{schemas_path}/reportesHistoricos/corregido/{a}.xlsx'\n",
    "    )\n",
    "\n",
    "    # Se almacenan el dataframe en una carpeta local\n",
    "    df.to_pickle(f'../dfsWithCorrectedSchema/reportesHistoricos/{a}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1c7e62",
   "metadata": {},
   "source": [
    "## 1.4. Datos de las calificaciones históricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6505388",
   "metadata": {},
   "outputs": [],
   "source": [
    "anios = ['2182','2191','2192','2201','2202','2211', '2212','2221','2222']\n",
    "folderDfsCorrectedSchema = '../dfsWithCorrectedSchema/calificacionesHistoricas/'\n",
    "if not os.path.exists(folderDfsCorrectedSchema):\n",
    "    os.makedirs(folderDfsCorrectedSchema)\n",
    "\n",
    "for a in anios:\n",
    "    # Se descarga el archivo y se corrige su schema on-the-fly\n",
    "    df = downloadAndCorrectSchema(\n",
    "        files['calificacionesHistoricas'][a],\n",
    "        USER,\n",
    "        PASSWORD,\n",
    "        f'Descargando los datos de las calificaciones históricas {a}...',\n",
    "        f'{schemas_path}/calificacionesHistoricas/corregido/{a}.xlsx'\n",
    "    )\n",
    "\n",
    "    # Se almacenan el dataframe en una carpeta local\n",
    "    df.to_pickle(f'../dfsWithCorrectedSchema/calificacionesHistoricas/{a}.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "616e5bb9d2ba2f1208497effc25f4ebc5e0ad553b2a26480dd09af8b3c6a242e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
